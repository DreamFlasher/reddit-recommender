{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "This file handles all preprocessing of the original file 'safe_links_all.gz'\n",
    "\n",
    "1. drop all non-image files\n",
    "2. retrieve comments for posts (currently disabled, due to memory leak) \n",
    "3. downloading corresponding image, associating with hash of url\n",
    "4. converting to fasttext format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-10 13:08:57 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gzip\n",
    "from collections import namedtuple\n",
    "import requests\n",
    "import traceback\n",
    "import hashlib\n",
    "import praw\n",
    "import wget\n",
    "from praw.models import MoreComments\n",
    "import logging\n",
    "import datetime\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', datefmt=\"%Y-%m-%d %H:%M:%S\", level=logging.INFO, stream=sys.stdout)\n",
    "import os\n",
    "import os.path\n",
    "from multiprocessing import Pool\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = namedtuple('row_raw', ['subreddit', 'submission_title', 'submitted_link', 'comments_link', 'short_name'])\n",
    "base_path = \"/mnt/marcel/\"\n",
    "\n",
    "reddit = praw.Reddit(user_agent='Comment Extraction',\n",
    "         client_id='BQD4SITRawON4Q', client_secret=\"noSAX9aSU3VRPowZnhTytXm8sOk\",\n",
    "         )\n",
    "\n",
    "def retrieve_file(url, filename):\n",
    "    if not os.path.isfile(filename):\n",
    "        try:\n",
    "            wget.download(url, filename, None)\n",
    "        except:\n",
    "            pass \n",
    "\n",
    "def retrieve_comments(link):\n",
    "    try:\n",
    "        comments = reddit.submission(url='https://www.reddit.com'+link).comments.list()\n",
    "        comments_string = \"\"\n",
    "        for comment in comments:\n",
    "            if not isinstance(comment, MoreComments):\n",
    "                comments_string += comment.body + \" \"\n",
    "        with gzip.open(base_path+'comments/%s.gz' % os.getpid(),'at') as f:\n",
    "            f.write(str([link, comments_string])+\"\\n\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "with gzip.open(base_path+'safe_links_all.gz','rt') as f, gzip.open(base_path+'safe_links_imgposts.gz','wt') as fout, Pool(processes=32) as pool:\n",
    "    for i, line in enumerate(f):\n",
    "        line = line.replace(',null]', ',\"\"]').replace(',null,', ',\"\",').replace('[null,', '[\"\",')\n",
    "        if i%1000000==0:  # total number of lines: 206669601\n",
    "            logging.info(i//1000000)\n",
    "        line_list = eval(line)  # convert the str(list) to a list, don't do this in production, as this has the danger of code injection\n",
    "        r = row._make(line_list)\n",
    "        submitted_link = r.submitted_link\n",
    "        if '?' in submitted_link:  # crude way to strip url params\n",
    "            submitted_link = submitted_link[:r.submitted_link.find('?', 0)]                \n",
    "\n",
    "        if submitted_link.endswith(\".jpg\") or submitted_link.endswith(\".png\") or submitted_link.endswith(\".jpeg\"):\n",
    "            imgurlhash = hashlib.sha256(r.submitted_link.encode('utf-8')).hexdigest()\n",
    "            suffix = \".jpg\"\n",
    "            if submitted_link.endswith(\".png\"):\n",
    "                suffix = \".png\"\n",
    "            imgurlhash += suffix\n",
    "\n",
    "            filename = base_path+\"img/\"+imgurlhash\n",
    "            pool.apply_async(retrieve_file, (r.submitted_link, filename))\n",
    "            #pool.apply_async(retrieve_comments, (r.comments_link, ))\n",
    "\n",
    "            outlist = list(r)\n",
    "            outlist.append(imgurlhash)                \n",
    "            fout.write(str(outlist)+\"\\n\")\n",
    "            \n",
    "            #with gzip.open(base_path+'subreddits/%s.gz' % r.subreddit,'at') as f:\n",
    "            #    f.write(r.submission_title+\"\\n\")\n",
    "\n",
    "            #outlist.append(comments_string)\n",
    "            #foutc.write(str(outlist)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = namedtuple('row_raw', ['subreddit', 'submission_title', 'submitted_link', 'comments_link', 'short_name', 'imgurlhash'])\n",
    "\n",
    "with open(base_path+'imgposts_fasttext.train', \"wt\") as ft_train, open(base_path+'imgposts_fasttext.valid', \"wt\") as ft_valid, gzip.open(base_path+'safe_links_imgposts.gz', \"rt\") as f: \n",
    "    for i, line in enumerate(f):\n",
    "        line_list = eval(line)  # convert the str(list) to a list, don't do this in production, as this has the danger of code injection\n",
    "        r = row._make(line_list)\n",
    "        output = \"__label__\" + r.subreddit + \" \" + \" \".join(gensim.utils.simple_preprocess(r.submission_title)) + \"\\n\"\n",
    "        if i%10==0:\n",
    "            ft_valid.write(output)\n",
    "        else:\n",
    "            ft_train.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
